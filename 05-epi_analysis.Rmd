# Epigenome-wide association analysis (EWAS)

<table><colgroup><col style="width: 100%" /></colgroup><thead><tr class="header"><th style="text-align: left;"><p>`r emo::ji("warning")` RESOURCES USED ALONG THIS SECTION</p></th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><p>From <a href="https://opal-demo.obiba.org/">https://opal-demo.obiba.org/</a> :</p></td></tr><tr class="even"><td style="text-align: left;"><table><thead><tr class="header"><th><p>STUDY</p></th><th><p>TABLE</p></th><th><p>PROFILE</p></th></tr></thead><tbody><tr class="odd"><td><p>cohort1</p></td><td><p>OMICS.GSE66351_1</p></td><td><p>omics</p></td></tr><tr 
class="odd"><td><p>cohort2</p></td><td><p>OMICS.GSE66351_2</p></td><td><p>omics</p></td></tr><tr 
</tbody></table></td></tr></tbody></table>

In this section we will illustrate how to perform an epigenome-wide association analysis (EWAS) using methylation data. EWAS requires basically the same statistical methods as those used in DGE. It should be noticed that the **pooled analysis** we are going to illustrate here can also be performed with transcriptomic data, however the data needs to be harmonized beforehand to ensure each study has the same range values. For EWAS where methylation is measured using beta values (e.g CpG data are in the range 0-1) this is not a problem. In any case, adopting the **meta-analysis** approach could be a safe option without the need of harmonization. 

Moreover, we encourage to perform **pooled analysis** only on the significant hits obtained by the **meta-analysis**, since it is a much slower methodology.

The data used in this section has been downloaded from [GEO](https://www.ncbi.nlm.nih.gov/geo/) (accession number GSE66351) which contains DNA methylation profiling (Illumina 450K array). Data corresponds to CpGs beta values measured in the superior temporal gyrus and prefrontal cortex brain regions of patients with Alzheimer's. 

This kind of data is encapsulated on a type of R object called `ExpressionSet`, this objects are part of the [BioConductor project](https://www.bioconductor.org/) and are meant to contain different sources of genomic data, alongside the genomic data they can also contain the phenotypes and metadata associated to a study. Researchers who are not familiar with `ExpressionSet` can find further information [here](https://www.bioconductor.org/packages/release/bioc/vignettes/Biobase/inst/doc/ExpressionSetIntroduction.pdf).

The data that we will be using along this section is an `ExpressionSet` objects. Notice that genomic data is encoded as beta-values that ensure data harmonization across studies.

In order to illustrate how to perform data analyses using federated data, we have split the data into two synthetic cohorts (split by individuals). We have created two resources on the demo Opal server called `GSE66351_1` and `GSE66351_2` respectively. They can be found inside the `OMICS` project. Some summaries of the datasets are the following:

|                               | Cohort 1 | Cohort 2 |   Total |
|-------------------------------|---------:|---------:|--------:|
| Number of CpGs                |  481,868 |  481,868 | 481,868 |
| Number of individuals         |      100 |       90 |     190 |
| Number of covariates          |       49 |       49 |      49 |
| Number of annotation features |       37 |       37 |      37 |

The structure used is illustrated on the following figure.

```{r ewasProposal, echo=FALSE, fig.cap="Proposed infrastructure to perform EWAS studies.", fig.align='center'}
knitr::include_graphics("fig/ewas_structure.png")
```

The data analyst corresponds to the “RStudio” session, which through DataSHIELD Interface (DSI) connects with the Opal server. The Opal servers contain a resource that correspond to the GEO:GSE66351 `ExpressionSet` (subseted by individuals).

We will illustrate the following use cases:

- Single CpG pooled analysis
- Multiple CpGs pooled analysis
- Full genome meta-analysis
- Full genome meta-analysis adjusting for surrogate variables

## Initial steps for all use cases

### Connection to the Opal server

We have to create an Opal connection object to the different cohorts server. We do that using the following functions.

```{r ewas_ds_login, message=FALSE, warning=FALSE}
require('DSI')
require('DSOpal')
require('dsBaseClient')
require('dsOmicsClient')

builder <- DSI::newDSLoginBuilder()
builder$append(server = "cohort1", url = "https://opal-demo.obiba.org/",
               user =  "dsuser", password = "P@ssw0rd",
               driver = "OpalDriver", profile = "omics")
builder$append(server = "cohort2", url = "https://opal-demo.obiba.org/",
               user =  "dsuser", password = "P@ssw0rd",
               driver = "OpalDriver", profile = "omics")
logindata <- builder$build()
conns <- DSI::datashield.login(logins = logindata)
```

It is important to note that in this use case, we are only using one server (https://opal-demo.obiba.org/), on this server there are all the resources that correspond to the different cohorts. On a more real scenario each one of the `builder$append` instructions would be connecting to a different server.

### Assign the `ExpressionSet` resource

Now that we have created a connection object to the different Opals, we have started two R sessions, our analysis will take place on those remote sessions, so we have to load the data into them.

In this use case we will use 2 different resources from the `OMICS` project hosted on the demo Opal server. The names of the resources are  `GSE66351_X` (where `X` is the cohort identifier `1`/`2`). Following the Opal syntax, we will refer to them using the string `OMICS.GSE66351_X`.

We have to refer specifically to each different server by using `conns[X]`, this allows us to communicate with the server of interest to indicate to it the resource that it has to load.

```{r ewas_load_resource}
# Cohort 1 resource load
DSI::datashield.assign.resource(conns[1], "eSet_resource", "OMICS.GSE66351_1")

# Cohort 2 resource load
DSI::datashield.assign.resource(conns[2], "eSet_resource", "OMICS.GSE66351_2")
```

Now we have assigned all the resources named into our remote R sessions. We have assigned them to the variables called `eSet_resource`. To verify this step has been performed correctly, we can use the `ds.class` function to check for their class and that they exist on the remote sessions.

```{r ewas_check_resource}
ds.class("eSet_resource")
```

We can see that the object `eSet_resource` exists in both servers.

Finally the resource is resolved to retrieve the data in the remote sessions.

```{r ewas_resolve_resource}
DSI::datashield.assign.expr(conns = conns, symbol = "eSet",
                            expr = as.symbol("as.resource.object(eSet_resource)"))
```

Now we have resolved the resource named `eSet_resource` into our remote R session. The object retrieved has been assigned into the variable named `eSet`. We can check the process was successful as we did before.

```{r ewas_check_resolved_resource}
ds.class("eSet")
```

### Inspect the `ExpressionSet` {#ewas-inspect}

Feature names can be returned by:

```{r ewas_features}
fn <- ds.featureNames("eSet")
lapply(fn, head)
```

Experimental phenotypes variables can be obtained by:

```{r ewas_variables}
fn <- ds.varLabels("eSet")
lapply(fn, head)
```

The columns of the annotation can be obtained by:

```{r ewas_annotation}
fn <- ds.fvarLabels("eSet")
lapply(fn, head)
```

## Single CpG pooled analysis

Once the methylation data have been loaded into the opal server, we can perform different type of analyses using functions from the `dsOmicsClient` package. Let us start by illustrating how to analyze a single CpG from two cohorts by using an approach that is mathematically equivalent to placing all individual-level (pooled).

```{r ewas_single_pooled}
ans <- ds.lmFeature(feature = "cg07363416", 
                    model = ~ diagnosis + Sex, 
                    Set = "eSet",
                    datasources = conns)
ans
```

## Multiple CpGs pooled analysis

The same analysis can be performed for multiple features. This process can be parallelized using `mclapply` function from the multicore package (only works on GNU/Linux, not on Windows).

```{r ewas_multiple, eval=FALSE}
ans <- ds.lmFeature(feature = c("cg00000029", "cg00000108", "cg00000109", "cg00000165"),
                    model = ~ diagnosis + Sex, 
                    Set = "eSet",
                    datasources = conns,
                    mc.cores = 20)
```

If the `feature` argument is not supplied, all the features will be analyzed, please note that this process can be extremely slow if there is a huge number of features; for example, on the case we are illustrating we have over 400K features, so this process would take too much time.

If all the features are to be studied, we recommend switching to meta-analysis methods. More information on the next section.

## Full genome meta-analysis

We can adopt another strategy that is to run a `glm` of each feature independently at each study using `limma` package (which is really fast) and then combine the results (i.e. **meta-analysis** approach).

```{r ewas_limma}
ans.limma <- ds.limma(model = ~ diagnosis + Sex,
                      Set = "eSet", 
                      datasources = conns)
```

Then, we can visualize the top genes at each study (i.e server) by:

```{r ewas_limma_top}
lapply(ans.limma, head)
```

The annotation can be added by using the argument `annotCols`. It should be a vector with the columns of the annotation available in the `ExpressionSet` or `RangedSummarizedExperiment` that want to be showed. To obtain the available annotation columns revisit #ewas-inspect.

```{r ewas_limma_annotated}
ans.limma.annot <- ds.limma(model = ~ diagnosis + Sex,
                            Set = "eSet", 
                            annotCols = c("CHR", "UCSC_RefGene_Name"),
                            datasources = conns)
lapply(ans.limma.annot, head)
```

Then, the last step is to meta-analyze the results. Different methods can be used to this end. We have implemented a method that meta-analyze the p-pvalues of each study as follows:

```{r ewas_limma_meta}
ans.meta <- metaPvalues(ans.limma)
ans.meta
```

We can verify that the results are pretty similar to those obtained using pooled analyses. Here we compute the association for the top two CpGs:

```{r ewas_limma_meta_top_pooled}
res <- ds.lmFeature(feature = ans.meta$id[1:2], 
                     model = ~ diagnosis + Sex, 
                     Set = "eSet",
                     datasources = conns)
res
```

We can create a QQ-plot by using the function `qqplot` available in our package.

```{r ewas_limma_qq}
qqplot(ans.meta$p.meta)
```

Here In some cases inflation can be observed, so that, correction for cell-type or surrogate variables must be performed. We describe how we can do that in the next two sections.

## Adjusting for surrogate variables

The vast majority of omic studies require to control for unwanted variability. The surrogate variable analysis (SVA) can address this issue by estimating some hidden covariates that capture differences across individuals due to some artifacts such as batch effects or sample quality among others. The method is implemented in [SVA](https://bioconductor.org/packages/release/bioc/html/sva.html) package.

Performing this type of analysis using the `ds.lmFeature` function is not allowed since estimating SVA would require to implement a non-disclosive method that computes SVA from the different servers. This will be a future topic of the `dsOmicsClient`. For that reason we have to adopt a compromise solution which is to perform the SVA independently at each study. We use the `ds.limma` function to perform the analyses adjusted for SVA at each study.

```{r ewas_limma_sva}
ans.sva <- ds.limma(model = ~ diagnosis + Sex, 
                    Set = "eSet",
                    sva = TRUE, annotCols = c("CHR", "UCSC_RefGene_Name"))
ans.sva
```

Then, data can be combined meta-anlyzed as follows:

```{r ewas_limma_sva_meta}
ans.meta.sv <- metaPvalues(ans.sva)
ans.meta.sv
```

And we can revisit the qqplot:

```{r ewas_limma_sva_meta_qq}
qqplot(ans.meta.sv$p.meta)
```

The DataSHIELD session must be closed by:

```{r}
datashield.logout(conns)
```

