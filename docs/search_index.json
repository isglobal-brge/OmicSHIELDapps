[["Exposome_HELIX_analysis.html", "2 Exposome data analysis in HELIX data. 2.1 Getting started. 2.2 Data formatting and manipulation in DataSHIELD. 2.3 Implementation of ExWAS in DataSHIELD. 2.4 Feature selection with penalized methods", " 2 Exposome data analysis in HELIX data. The main aim of this chapter is to illustrate how to perform exposome analyses on a multi-centre study in a non-disclosive way using DataSHIELD. Particularly, we will cover how to apply some of the most frequently employed techniques in exposome analysis such is the case of Exposome Wide Association Analysis (ExWAS) or variable selection with penalized regressions. To illustrate the power and possibilities emanating from DataSHIELD in the context of exposome analysis, we will replicate some of the analyses presented in the work of (Warembourg et al. 2019), in which the association between a wide range of prenatal and postnatal exposures and blood pressure (BP) in children is investigated. For this purpose, we will use the exposome data from the HELIX project previously described (@ref(Exposome_HELIX_Data)), and two DataSHIELD packages designed for such purposes; (1) the “dsExposomeClient” (CITA) from our research group, and (2) the dsMTL (Federated Multi-Task Learning based on DataSHIELD) from (Cao2021.08.26.457778?). In this tutorial, we will give a general overview of how to implement some of the main functions of these packages in the context of a multi-centre exposome study. Some topics covered in this tutorial include: 1) Setting up the R environment for working with these packages in DataSHIELD, 2) Loading the HELIX showcase data from an Opal server into the DataSHIELD environment, and 3) Application of ExWAS for multiple association analysis, and Lasso regression for variable-selection. 2.1 Getting started. In this section, we will describe how to configure R and DataSHIELD with the needed packages to carry out proposed of analyses in remote. First, it is necessary to install the client-side version of the following DataSHIELD/Opal integration packages. install.packages(&#39;DSOpal&#39;, dependencies=TRUE) install.packages(&quot;DSI&quot;, dependencies=TRUE) Make sure you also install the DataSHIELD client-side version of the packages “dsBaseClient” and “dsBase”. The “dsBaseClient” package needs to be a client which is version 6.0.0 or higher. install.packages(&quot;dsBase&quot;, dependencies=TRUE) install.packages(&quot;dsBaseClient&quot;, repos = c(&quot;http://cran.datashield.org&quot;, &quot;https://cloud.r-project.org/&quot;), dependencies = TRUE) Then, install the client-side version of the “dsExposomeClient” and “dsMTL” packages directly from GitHub. install.packages(&quot;devtools&quot;) library(&quot;devtools&quot;) devtools::install_github(&quot;transbioZI/dsMTLClient&quot;) devtools::install_github(&#39;isglobal-brge/dsExposomeClient@1.1.2&#39;) Once installations are complete, all the packages are loaded as usual. library(DSI) library(DSOpal) library(dsBaseClient) library(dsMTLClient) library(dsExposomeClient) In this tutorial, we will use the Opal BRGE site to illustrate how to perform mentioned analyses in DataSHIELD. Details for accessing the server can be found below. We will employ an user who have DataSHIELD permissions to Opal servers called “dsuser. 2.2 Data formatting and manipulation in DataSHIELD. In this section, we will cover how to manipulate and prepare input data with DataSHIELD according to the needs of the functions available in the “dsExposomeClient” and “dsMTL” packages. We start by creating the connection to the opal server using an user who have DataSHIELD permissions to Opal servers (dsuser). Please, note that in our example, all datasets are hosted in the same Opal but each cohort sub-dataset is accessed separately. In the case each cohort dataset was available in a different opal, the way of login data would be the same but specifying different connection details. builder &lt;- DSI::newDSLoginBuilder() builder$append(server = &quot;BIB&quot;, url = &quot;https://datashield.isglobal.org/repo&quot;, user = &quot;jrgonzalez&quot;, password = &quot;Z2Z//B5&quot;, driver = &quot;OpalDriver&quot;, profile = &quot;rock-inma&quot;) builder$append(server = &quot;EDEN&quot;, url = &quot;https://datashield.isglobal.org/repo&quot;, user = &quot;jrgonzalez&quot;, password = &quot;Z2Z//B5&quot;, profile = &quot;rock-inma&quot;) builder$append(server = &quot;KANC&quot;, url = &quot;https://datashield.isglobal.org/repo&quot;, user = &quot;jrgonzalez&quot;, password = &quot;Z2Z//B5&quot;, profile = &quot;rock-inma&quot;) builder$append(server = &quot;MoBA&quot;, url = &quot;https://datashield.isglobal.org/repo&quot;, user = &quot;jrgonzalez&quot;, password = &quot;Z2Z//B5&quot;, profile = &quot;rock-inma&quot;) builder$append(server = &quot;Rhea&quot;, url = &quot;https://datashield.isglobal.org/repo&quot;, user = &quot;jrgonzalez&quot;, password = &quot;Z2Z//B5&quot;, profile = &quot;rock-inma&quot;) builder$append(server = &quot;INMASAB&quot;, url = &quot;https://datashield.isglobal.org/repo&quot;, user = &quot;jrgonzalez&quot;, password = &quot;Z2Z//B5&quot;, profile = &quot;rock-inma&quot;) logindata &lt;- builder$build() conns &lt;- DSI::datashield.login(logins = logindata) Next, we will load each of the resources available in the Opal server, corresponding to each cohort “exposomeSet”, using the DSI::datashield.assign.resource() function and each of the connections to the server created in the previous code chunk. This way, we assign all available resource objects in the Opal to an R object called “resource” in the DataSHIELD remote session. DSI::datashield.assign.resource(conns[1], &quot;resource&quot;, &quot;HELIX.postnatal_BIB&quot;) DSI::datashield.assign.resource(conns[2], &quot;resource&quot;, &quot;HELIX.postnatal_EDE&quot;) DSI::datashield.assign.resource(conns[3], &quot;resource&quot;, &quot;HELIX.postnatal_KAN&quot;) DSI::datashield.assign.resource(conns[4], &quot;resource&quot;, &quot;HELIX.postnatal_MOB&quot;) DSI::datashield.assign.resource(conns[5], &quot;resource&quot;, &quot;HELIX.postnatal_RHE&quot;) DSI::datashield.assign.resource(conns[6], &quot;resource&quot;, &quot;HELIX.postnatal_SAB&quot;) Next, we have to resolve the resources and retrieve the data in the remote session. For that, we will use the DSI::datashield.assign.expr() function. This function will assign the result of the execution of the argument “expr” to an R object called “exposome_set” in the Datashield remote session. In particular, we run the function as.resource.object(), which is the DataSHIELD function in charge of resolving resources (it coerces the resource to an internal data object that depends on the implementation of the object). As a result, we will get an R object (here named “exposome_Set”) containing the “exposomeSets” files for all cohorts. DSI::datashield.assign.expr(conns = conns, symbol = &quot;exposome_set&quot;, expr = as.symbol(&quot;as.resource.object(resource)&quot;)) Once we have loaded the resources, we have also to load each of the tables with additional phenotypes available for each cohort in the Opal server. For that purpose, we will use the DSI::datashield.assign.table() function, which assigns tables to an R object in the remote session (here named “pheno”). As a result, the “pheno” object will contain six data.frames corresponding to each of the tables with extra phenotypes for cohorts. DSI::datashield.assign.table(conns[1], &quot;pheno&quot;, &quot;HELIX.subclinical_cardio_BIB&quot;) DSI::datashield.assign.table(conns[2], &quot;pheno&quot;, &quot;HELIX.subclinical_cardio_EDE&quot;) DSI::datashield.assign.table(conns[3], &quot;pheno&quot;, &quot;HELIX.subclinical_cardio_KAN&quot;) DSI::datashield.assign.table(conns[4], &quot;pheno&quot;, &quot;HELIX.subclinical_cardio_MOB&quot;) DSI::datashield.assign.table(conns[5], &quot;pheno&quot;, &quot;HELIX.subclinical_cardio_RHE&quot;) DSI::datashield.assign.table(conns[6], &quot;pheno&quot;, &quot;HELIX.subclinical_cardio_SAB&quot;) To verify previous steps were performed correctly, we could use some descriptive functions on created objects. For example, we can check the names of the variables included in each object, and ensure this way that they exist on the remote session. #Which is the class of the remote R objects &quot;exposome_set&quot; and &quot;pheno&quot;: ds.class(&quot;exposome_set&quot;) $BIB [1] &quot;ExposomeSet&quot; attr(,&quot;package&quot;) [1] &quot;rexposome&quot; $EDEN [1] &quot;ExposomeSet&quot; attr(,&quot;package&quot;) [1] &quot;rexposome&quot; $KANC [1] &quot;ExposomeSet&quot; attr(,&quot;package&quot;) [1] &quot;rexposome&quot; $MoBA [1] &quot;ExposomeSet&quot; attr(,&quot;package&quot;) [1] &quot;rexposome&quot; $Rhea [1] &quot;ExposomeSet&quot; attr(,&quot;package&quot;) [1] &quot;rexposome&quot; $INMASAB [1] &quot;ExposomeSet&quot; attr(,&quot;package&quot;) [1] &quot;rexposome&quot; ds.class(&quot;pheno&quot;) $BIB [1] &quot;data.frame&quot; $EDEN [1] &quot;data.frame&quot; $KANC [1] &quot;data.frame&quot; $MoBA [1] &quot;data.frame&quot; $Rhea [1] &quot;data.frame&quot; $INMASAB [1] &quot;data.frame&quot; #Get the number of exposures, phenotypes and individuals in each file: ds.dim(&quot;pheno&quot;) $`dimensions of pheno in BIB` [1] 231 7 $`dimensions of pheno in EDEN` [1] 205 7 $`dimensions of pheno in KANC` [1] 207 7 $`dimensions of pheno in MoBA` [1] 291 7 $`dimensions of pheno in Rhea` [1] 200 7 $`dimensions of pheno in INMASAB` [1] 489 7 $`dimensions of pheno in combined studies` [1] 1623 7 # si se lanza en el chunk de primeras falla, si se vuelve a lanzar funciona. ds.dim(&quot;exposome_set&quot;) #Show the name of the columns available in the data.frames of the pheno object: ds.colnames(&quot;pheno&quot;) $BIB [1] &quot;HelixID&quot; &quot;hs_bp_sys&quot; &quot;hs_bp_dia&quot; &quot;hs_zsys_bp&quot; [5] &quot;hs_zdia_bp&quot; &quot;hs_hypertensive&quot; &quot;hs_waist&quot; $EDEN [1] &quot;HelixID&quot; &quot;hs_bp_sys&quot; &quot;hs_bp_dia&quot; &quot;hs_zsys_bp&quot; [5] &quot;hs_zdia_bp&quot; &quot;hs_hypertensive&quot; &quot;hs_waist&quot; $KANC [1] &quot;HelixID&quot; &quot;hs_bp_sys&quot; &quot;hs_bp_dia&quot; &quot;hs_zsys_bp&quot; [5] &quot;hs_zdia_bp&quot; &quot;hs_hypertensive&quot; &quot;hs_waist&quot; $MoBA [1] &quot;HelixID&quot; &quot;hs_bp_sys&quot; &quot;hs_bp_dia&quot; &quot;hs_zsys_bp&quot; [5] &quot;hs_zdia_bp&quot; &quot;hs_hypertensive&quot; &quot;hs_waist&quot; $Rhea [1] &quot;HelixID&quot; &quot;hs_bp_sys&quot; &quot;hs_bp_dia&quot; &quot;hs_zsys_bp&quot; [5] &quot;hs_zdia_bp&quot; &quot;hs_hypertensive&quot; &quot;hs_waist&quot; $INMASAB [1] &quot;HelixID&quot; &quot;hs_bp_sys&quot; &quot;hs_bp_dia&quot; &quot;hs_zsys_bp&quot; [5] &quot;hs_zdia_bp&quot; &quot;hs_hypertensive&quot; &quot;hs_waist&quot; #Since the &quot;exposome_set&quot; object contains exposomeSet-type files for each cohort, the process for retrieving the names of variables is slightly different. For that purpose we have several functions from the _ds.ExposomeClient package_ called ds.phenotypeNames() and ds.exposome_variables(). #Get the name of the phenotypes available in the exposomeSet file for the EDEN cohort. ds.phenotypeNames(&quot;exposome_set&quot;, conns)$EDEN [1] &quot;.id.1&quot; &quot;.imp.1&quot; [3] &quot;HelixID&quot; &quot;SampleID&quot; [5] &quot;hs_bmicat_None&quot; &quot;hs_c_bmi_None&quot; [7] &quot;hs_c_height_None&quot; &quot;hs_c_weight_None&quot; [9] &quot;hs_zheight_None&quot; &quot;hs_zweight_None&quot; [11] &quot;hs_creatinine_c_None&quot; &quot;hs_creatinine_cg_None&quot; [13] &quot;h_cereal_post_Log&quot; &quot;h_dairy_post_Log&quot; [15] &quot;h_fastfood_post_Log&quot; &quot;h_fish_post_Log&quot; [17] &quot;h_fruit_post_Log&quot; &quot;h_legume_post_Log&quot; [19] &quot;h_meat_post_Log&quot; &quot;h_nonalc_post_Log&quot; [21] &quot;h_sugar_post_Log&quot; &quot;h_veg_post_Log&quot; [23] &quot;hs_child_age_days_None&quot; &quot;hs_chol_cperc_None_v2&quot; [25] &quot;hs_hdlchol_c_None&quot; &quot;hs_ldlchol_c_None&quot; [27] &quot;hs_phospho_c_None&quot; &quot;hs_phospho_cperc_None_v2&quot; [29] &quot;hs_totchol_c_None&quot; &quot;hs_totfat_cperc_None_v2&quot; [31] &quot;hs_triglyc_c_None&quot; &quot;hs_triglyc_cperc_None_v2&quot; [33] &quot;hs_cmbl_None&quot; &quot;hs_wifi_hm_None&quot; [35] &quot;h_nursery_Sqrt&quot; &quot;h_nurseryage_None&quot; [37] &quot;h_solidfoods_None&quot; &quot;h_ethnicity_c_None&quot; [39] &quot;hs_wrk_p5y_None&quot; &quot;h_mbmi_None&quot; [41] &quot;h_mbmic_None&quot; &quot;h_mheight_None&quot; [43] &quot;h_mweight_None&quot; &quot;hs_wgtgain_None&quot; [45] &quot;e3_bwc_None&quot; &quot;e3_gac_None&quot; [47] &quot;e3_pi_None&quot; &quot;e3_premac_None&quot; [49] &quot;h_cesarean_None&quot; &quot;h_spon_None&quot; [51] &quot;hs_creatinine_m_Log2&quot; &quot;hs_creatinine_mg_Log2&quot; [53] &quot;e3_sex_None&quot; &quot;e3_yearbir_None&quot; [55] &quot;h_age_None&quot; &quot;h_cohort&quot; [57] &quot;h_edufc_None&quot; &quot;h_edumc_None&quot; [59] &quot;h_native_None&quot; &quot;h_parity_None&quot; [61] &quot;h_trimcon_None&quot; &quot;hs_bf_None&quot; [63] &quot;hs_bfdur_Log&quot; &quot;hs_chol_mperc_None_v2&quot; [65] &quot;hs_hdlchol_m_None&quot; &quot;hs_ldlchol_m_None&quot; [67] &quot;hs_phospho_m_None&quot; &quot;hs_phospho_mperc_None_v2&quot; [69] &quot;hs_totchol_m_None&quot; &quot;hs_totfat_mperc_None_v2&quot; [71] &quot;hs_triglyc_m_None&quot; &quot;hs_triglyc_mperc_None_v2&quot; [73] &quot;h_ivf_None&quot; &quot;h_pdia_None&quot; [75] &quot;h_pecl_None&quot; &quot;h_phta_None&quot; [77] &quot;h_crowding_None&quot; &quot;h_fage_None&quot; [79] &quot;h_marital_None&quot; &quot;h_mwork_None&quot; [81] &quot;h_urban_preg_None&quot; &quot;hs_wrk_m_None&quot; #Get the name of the exposures available in the exposomeSet file for the EDEN cohort. ds.exposome_variables(&quot;exposome_set&quot; , target=&quot;exposures&quot;)$EDEN [1] &quot;FAS_cat_None&quot; &quot;h_Absorbance_Log&quot; [3] &quot;h_Benzene_Log&quot; &quot;h_bfdur_Ter&quot; [5] &quot;h_NO2_Log&quot; &quot;h_PM_Log&quot; [7] &quot;h_TEX_Log&quot; &quot;hs_accesslines300_h_dic0&quot; [9] &quot;hs_accesspoints300_h_Log&quot; &quot;hs_as_c_Log2&quot; [11] &quot;hs_bakery_prod_Ter&quot; &quot;hs_beverages_Ter&quot; [13] &quot;hs_blueyn300_h_None&quot; &quot;hs_bpa_cadj_Log2&quot; [15] &quot;hs_break_cer_Ter&quot; &quot;hs_builtdens300_h_Sqrt&quot; [17] &quot;hs_bupa_cadj_Log2&quot; &quot;hs_caff_drink_Ter&quot; [19] &quot;hs_cd_c_Log2&quot; &quot;hs_co_c_Log2&quot; [21] &quot;hs_connind300_h_Log&quot; &quot;hs_contactfam_3cat_num_None&quot; [23] &quot;hs_cotinine_cdich_None&quot; &quot;hs_cs_c_Log2&quot; [25] &quot;hs_cu_c_Log2&quot; &quot;hs_dairy_Ter&quot; [27] &quot;hs_dde_cadj_Log2&quot; &quot;hs_ddt_cadj_Log2&quot; [29] &quot;hs_dep_cadj_Log2&quot; &quot;hs_detp_cadj_Log2&quot; [31] &quot;hs_distinvnear1_h_Log&quot; &quot;hs_dmdtp_cdich_None&quot; [33] &quot;hs_dmp_cadj_Log2&quot; &quot;hs_dmtp_cadj_Log2&quot; [35] &quot;hs_etpa_cadj_Log2&quot; &quot;hs_fastfood_Ter&quot; [37] &quot;hs_fdensity300_h_Log&quot; &quot;hs_frichness300_h_None&quot; [39] &quot;hs_globalexp2_None&quot; &quot;hs_greenyn300_h_None&quot; [41] &quot;hs_hcb_cadj_Log2&quot; &quot;hs_hg_c_Log2&quot; [43] &quot;hs_hm_pers_None&quot; &quot;hs_hum_mt_hs_h_None&quot; [45] &quot;hs_k_c_Log2&quot; &quot;hs_KIDMED_None&quot; [47] &quot;hs_landuseshan300_h_None&quot; &quot;hs_lden_cat_h_None&quot; [49] &quot;hs_ln_cat_h_None&quot; &quot;hs_mbzp_cadj_Log2&quot; [51] &quot;hs_mecpp_cadj_Log2&quot; &quot;hs_mehhp_cadj_Log2&quot; [53] &quot;hs_mehp_cadj_Log2&quot; &quot;hs_meohp_cadj_Log2&quot; [55] &quot;hs_mep_cadj_Log2&quot; &quot;hs_mepa_cadj_Log2&quot; [57] &quot;hs_mg_c_Log2&quot; &quot;hs_mibp_cadj_Log2&quot; [59] &quot;hs_mn_c_Log2&quot; &quot;hs_mnbp_cadj_Log2&quot; [61] &quot;hs_mo_c_Log2&quot; &quot;hs_mvpa_prd_alt_None&quot; [63] &quot;hs_na_c_Log2&quot; &quot;hs_ndvi100_h_None&quot; [65] &quot;hs_no2_yr_hs_h_Log&quot; &quot;hs_ohminp_cadj_Log2&quot; [67] &quot;hs_org_food_Ter&quot; &quot;hs_oxbe_cadj_Log2&quot; [69] &quot;hs_oxominp_cadj_Log2&quot; &quot;hs_participation_3cat_None&quot; [71] &quot;hs_pb_c_Log2&quot; &quot;hs_pbde153_cadj_Log2&quot; [73] &quot;hs_pbde47_cadj_Log2&quot; &quot;hs_pcb118_cadj_Log2&quot; [75] &quot;hs_pcb138_cadj_Log2&quot; &quot;hs_pcb153_cadj_Log2&quot; [77] &quot;hs_pcb170_cadj_Log2&quot; &quot;hs_pcb180_cadj_Log2&quot; [79] &quot;hs_pet_cat_r2_None&quot; &quot;hs_pet_dog_r2_None&quot; [81] &quot;hs_pet_None&quot; &quot;hs_pfhxs_c_Log2&quot; [83] &quot;hs_pfna_c_Log2&quot; &quot;hs_pfoa_c_Log2&quot; [85] &quot;hs_pfos_c_Log2&quot; &quot;hs_pfunda_c_Log2&quot; [87] &quot;hs_pm10_yr_hs_h_None&quot; &quot;hs_pm25_yr_hs_h_None&quot; [89] &quot;hs_pm25abs_yr_hs_h_Log&quot; &quot;hs_popdens_h_Sqrt&quot; [91] &quot;hs_proc_meat_Ter&quot; &quot;hs_prpa_cadj_Log2&quot; [93] &quot;hs_readymade_Ter&quot; &quot;hs_sd_wk_None&quot; [95] &quot;hs_se_c_Log2&quot; &quot;hs_smk_parents_None&quot; [97] &quot;hs_tl_cdich_None&quot; &quot;hs_tm_mt_hs_h_None&quot; [99] &quot;hs_total_bread_Ter&quot; &quot;hs_total_cereal_Ter&quot; [101] &quot;hs_total_fish_Ter&quot; &quot;hs_total_fruits_Ter&quot; [103] &quot;hs_total_lipids_Ter&quot; &quot;hs_total_meat_Ter&quot; [105] &quot;hs_total_potatoes_Ter&quot; &quot;hs_total_sweets_Ter&quot; [107] &quot;hs_total_veg_Ter&quot; &quot;hs_total_yog_Ter&quot; [109] &quot;hs_trafload_h_pow1over3&quot; &quot;hs_trafnear_h_pow1over3&quot; [111] &quot;hs_trcs_cadj_Log2&quot; &quot;hs_uvdvf_mt_hs_h_None&quot; [113] &quot;hs_walkability_mean_h_None&quot; &quot;hs_zn_c_Log2&quot; [115] &quot;PSS_4_Score_None&quot; As we can observe from the previous descriptive, the number of individuals available in each of the cohort data.frames from the “pheno” object is different from the number of subjects available in each of the cohort exposomeSets from the “exposome_set” R object. To work only with a single exposomeSet file per cohort, we will now merge the additional phenotype data available in “pheno” to the outcomes already available in “exposome_set”. To do that, there is a function from the “dsExposomeClient” package called ds.addPhenoData2ExposomeSet(). This function add new phenotype data contained on a data.frame to an ExposomeSet. The ExposomeSet may or may not already have phenotype data. If the data.frame contains a phenotype already present on the ExposomeSet, the server function will throw an exception. The phenotypes data.frame has to contain an ID column which does not need to contain exactly the same individuals as the ExposomeSet, only the matching individuals will be updated, no new individuals will be introduced or removed from the ExposomeSet. # We will employ the HelixID variable as the identifier to match subjects from each dataset. ds.addPhenoData2ExposomeSet(&quot;exposome_set&quot;, &quot;pheno&quot;, identifier_ExposomeSet = &quot;HelixID&quot;, identifier_new_phenotypes = &quot;HelixID&quot;) We can check the process has been conducted successfully by exploring the dimensions of the new exposomeSets files created per cohort. ds.dim(&quot;exposome_set&quot;) $`dimensions of exposome_set in BIB` exposures samples phenotyes 115 205 88 $`dimensions of exposome_set in EDEN` exposures samples phenotyes 115 198 88 $`dimensions of exposome_set in KANC` exposures samples phenotyes 115 204 88 $`dimensions of exposome_set in MoBA` exposures samples phenotyes 115 272 88 $`dimensions of exposome_set in Rhea` exposures samples phenotyes 115 199 88 $`dimensions of exposome_set in INMASAB` exposures samples phenotyes 115 223 88 $`dimensions of exposome_set in combined studies` exposures samples 690 205 #We can also check if there is metadata available in each expsomeSet file describing the families of exposomes. ds.familyNames(&quot;exposome_set&quot;) $BIB [1] &quot;Socio-eco capital_Fac&quot; &quot;Indoor air&quot; &quot;Lifestyle&quot; [4] &quot;Built Environment&quot; &quot;Metals&quot; &quot;Natural Spaces_fac&quot; [7] &quot;Phenols&quot; &quot;Cotinine&quot; &quot;OCs&quot; [10] &quot;OP Pesticides&quot; &quot;Traffic&quot; &quot;OP Pesticides_fac&quot; [13] &quot;Tobacco Smoke_fac&quot; &quot;Socio-eco capital&quot; &quot;Meteorological&quot; [16] &quot;Essential minerals&quot; &quot;Noise_fac&quot; &quot;Phthalates&quot; [19] &quot;Natural Spaces&quot; &quot;Air Pollution&quot; &quot;PBDEs&quot; [22] &quot;Lifestyle_fac&quot; &quot;PFASs&quot; $EDEN [1] &quot;Socio-eco capital_Fac&quot; &quot;Indoor air&quot; &quot;Lifestyle&quot; [4] &quot;Built Environment&quot; &quot;Metals&quot; &quot;Natural Spaces_fac&quot; [7] &quot;Phenols&quot; &quot;Cotinine&quot; &quot;OCs&quot; [10] &quot;OP Pesticides&quot; &quot;Traffic&quot; &quot;OP Pesticides_fac&quot; [13] &quot;Tobacco Smoke_fac&quot; &quot;Socio-eco capital&quot; &quot;Meteorological&quot; [16] &quot;Essential minerals&quot; &quot;Noise_fac&quot; &quot;Phthalates&quot; [19] &quot;Natural Spaces&quot; &quot;Air Pollution&quot; &quot;PBDEs&quot; [22] &quot;Lifestyle_fac&quot; &quot;PFASs&quot; $KANC [1] &quot;Socio-eco capital_Fac&quot; &quot;Indoor air&quot; &quot;Lifestyle&quot; [4] &quot;Built Environment&quot; &quot;Metals&quot; &quot;Natural Spaces_fac&quot; [7] &quot;Phenols&quot; &quot;Cotinine&quot; &quot;OCs&quot; [10] &quot;OP Pesticides&quot; &quot;Traffic&quot; &quot;OP Pesticides_fac&quot; [13] &quot;Tobacco Smoke_fac&quot; &quot;Socio-eco capital&quot; &quot;Meteorological&quot; [16] &quot;Essential minerals&quot; &quot;Noise_fac&quot; &quot;Phthalates&quot; [19] &quot;Natural Spaces&quot; &quot;Air Pollution&quot; &quot;PBDEs&quot; [22] &quot;Lifestyle_fac&quot; &quot;PFASs&quot; $MoBA [1] &quot;Socio-eco capital_Fac&quot; &quot;Indoor air&quot; &quot;Lifestyle&quot; [4] &quot;Built Environment&quot; &quot;Metals&quot; &quot;Natural Spaces_fac&quot; [7] &quot;Phenols&quot; &quot;Cotinine&quot; &quot;OCs&quot; [10] &quot;OP Pesticides&quot; &quot;Traffic&quot; &quot;OP Pesticides_fac&quot; [13] &quot;Tobacco Smoke_fac&quot; &quot;Socio-eco capital&quot; &quot;Meteorological&quot; [16] &quot;Essential minerals&quot; &quot;Noise_fac&quot; &quot;Phthalates&quot; [19] &quot;Natural Spaces&quot; &quot;Air Pollution&quot; &quot;PBDEs&quot; [22] &quot;Lifestyle_fac&quot; &quot;PFASs&quot; $Rhea [1] &quot;Socio-eco capital_Fac&quot; &quot;Indoor air&quot; &quot;Lifestyle&quot; [4] &quot;Built Environment&quot; &quot;Metals&quot; &quot;Natural Spaces_fac&quot; [7] &quot;Phenols&quot; &quot;Cotinine&quot; &quot;OCs&quot; [10] &quot;OP Pesticides&quot; &quot;Traffic&quot; &quot;OP Pesticides_fac&quot; [13] &quot;Tobacco Smoke_fac&quot; &quot;Socio-eco capital&quot; &quot;Meteorological&quot; [16] &quot;Essential minerals&quot; &quot;Noise_fac&quot; &quot;Phthalates&quot; [19] &quot;Natural Spaces&quot; &quot;Air Pollution&quot; &quot;PBDEs&quot; [22] &quot;Lifestyle_fac&quot; &quot;PFASs&quot; $INMASAB [1] &quot;Socio-eco capital_Fac&quot; &quot;Indoor air&quot; &quot;Lifestyle&quot; [4] &quot;Built Environment&quot; &quot;Metals&quot; &quot;Natural Spaces_fac&quot; [7] &quot;Phenols&quot; &quot;Cotinine&quot; &quot;OCs&quot; [10] &quot;OP Pesticides&quot; &quot;Traffic&quot; &quot;OP Pesticides_fac&quot; [13] &quot;Tobacco Smoke_fac&quot; &quot;Socio-eco capital&quot; &quot;Meteorological&quot; [16] &quot;Essential minerals&quot; &quot;Noise_fac&quot; &quot;Phthalates&quot; [19] &quot;Natural Spaces&quot; &quot;Air Pollution&quot; &quot;PBDEs&quot; [22] &quot;Lifestyle_fac&quot; &quot;PFASs&quot; 2.3 Implementation of ExWAS in DataSHIELD. As we said, the main aim of this chapter is to illustrate how to perform exposome analyses on a multi-centre study in a non-disclosive way using DataSHIELD. In this subsection, we will cover how to apply Exposome Wide Association Analysis (ExWAS) in the prepared data from the HELIX project. For that, we will be reproducing some of the analyses conducted in (Warembourg et al. 2019), in which the association between a wide range of postnatal exposures and blood pressure (BP) phenotypes in children was investigated. In the childhood period, this work identified a bulk of external and internal exposures affecting both diastolic and systolic blood pressure measurements (Figure 1). Here, for simplification, we will replicate only some of the findings reported for systolic blood pressure (framed in red in the Figure 1). Particularly, we will focus in the study of exposures belonging to the family of “Organochlorine compounds (OCs)”. Figure 2.1: Figure 1. Environmental-Wide Association Study Between Postnatal Exposome and Systolic and Diastolic Blood Pressure in the HELIX cohort (Warembourg C et al. (2019)(Warembourg et al. 2019). The exact estimates and 95% confidence intervals (CIs) obtained for these exposures are presented in 2.1. Importantly, these analyses were properly adjusted by confounders such as child age, child height, child sex, child cohort, mother’s age at the moment of birth, mother’s BMI at the moment of birth and paternal country of origin. Table 2.1: Postnatal ExWAS and systolic and diastolic blood pressure (corrected p-value threshold=0.00068). Systolic Blood Pressure Diastolic Blood Pressure Exposure Beta [95% CI] P-value ————————— ———————————-: ———————————-: DDE -2.1 [-2.92; -1.28] 0.00000 HCB -2.05 [-2.82; -1.29] 0.00000 PCB 153 -1.90 [-2.85; -0.95] 0.00009 PCB 170 -1.73 [-2.73; -0.73] 0.00068 PCBs (sum) -1.93 [-2.94; -0.92] 0.00018 Before replicating these findings through ExWAS, it is advisable to extract some basic exploratory analysis on the outcome and confounders to be used in the models. For that, we can use the function ds.exposome_summary() from the package “ds.ExposomeClient”, which gives some basic summary statistics for both numeric and categorical variables. # Retrieve basic summary statistics for the main outcome under study (systolic blood pressure). ds.exposome_summary(&quot;exposome_set&quot;, &quot;hs_bp_sys&quot;, conns) # Retrieve basic summary statistics for the confounders to be included in the model. ds.exposome_summary(&quot;exposome_set&quot;, &quot;hs_child_age_days_None&quot;, conns) ds.exposome_summary(&quot;exposome_set&quot;, &quot;hs_c_height_None&quot;, conns) ds.exposome_summary(&quot;exposome_set&quot;, &quot;e3_sex_None&quot;, conns) ds.exposome_summary(&quot;exposome_set&quot;, &quot;h_cohort&quot;, conns) ds.exposome_summary(&quot;exposome_set&quot;, &quot;h_age_None&quot;, conns) ds.exposome_summary(&quot;exposome_set&quot;, &quot;h_mbmi_None&quot;, conns) ds.exposome_summary(&quot;exposome_set&quot;, &quot;h_native_None&quot;, conns) From the previous chunk, we identify some problems with the variable parent’s country of origin, for which it seems there is no available data in some of the cohorts (ERROR: “INVALID object!”). Considering this, we will discard it from analysis, since it would give errors when incorporated into the models. At this point, we are ready to apply the ExWAS on systolic blood pressure focusing in the particular set of exposures belonging the OCs family. For that, we have the ds.exwas() function from the “ds.ExposomeClient” package. As we will see, there are several ways of applying an ExWAS in DataSHIELD (pooled vs. meta), and the chosen method will depend on the characteristics of each project. Both methods are based on fitting different generalized linear models (GLMs) for each feature/exposure when assessing association with the phenotype of interest. The “virtually” pooled approach is recommended when the user wants to analyze data from different sources and obtain results as if the data were located in a single computer. It should be noticed that this method is not recommended when data are not properly harmonized or comparable between cohorts, whatever the reason. On the other hand, the federated meta-analysis approach performs an ExWAS on every study server to later meta-analyse the results. Thanks to that, it overcomes the limitations raised when performing pooled analysis. In the next chunk of code, we present how to apply both types of ExWAS to the HELIX data. Since in our example, for simplification, we focused only on OCs exposures, it will be vital that our exposomeSets count on metadata as a description file. This will allow us to use the “exposure_family” argument, in the ds.exwas() function, in which we can indicate the family group of exposures to restrict our analysis to. Other arguments available in the ds.exwas() function include the “family” argument, which refers to the type of link function to be used in the GLM (e.g., gaussian for continuous outcomes, binary for binary outomes, or poisson for counts). It’s important to note that if the family argument does not match with the nature of the data available in the phenotype, the ExWAS will fail. In the next chunk of code, we show how to apply ExWAS on our data following both approaches. #ExWAS with meta-analysis approach (without covariables). Estimated execution time: approx. 4.331925 mins start_time &lt;- Sys.time() res.meta &lt;- ds.exwas(&#39;hs_bp_sys ~ 1&#39;, type = &quot;meta&quot;, exposures_family = &quot;OCs&quot;, Set = &#39;exposome_set&#39;, family = &#39;gaussian&#39;) [1] &quot;The computation of threshold for effective tests was not successful. NAs were generated on the correlation matrix so the calculation was aborted.&quot; end_time &lt;- Sys.time() end_time - start_time Time difference of 4.848315 mins res.meta $BIB $BIB$exwas_results exposure family coefficient minE maxE p.value 1 hs_dde_cadj_Log2 OCs -1.6438877 -3.541887 0.2541115 0.08959152 2 hs_ddt_cadj_Log2 OCs 0.1091568 -2.060320 2.2786341 0.92144381 3 hs_hcb_cadj_Log2 OCs -6.1180786 -13.452346 1.2161893 0.10205803 4 hs_pcb118_cadj_Log2 OCs -7.1454343 -13.740344 -0.5505245 0.03370559 5 hs_pcb138_cadj_Log2 OCs -2.8928741 -7.834245 2.0484967 0.25119960 6 hs_pcb153_cadj_Log2 OCs -3.0742528 -8.365768 2.2172625 0.25483017 7 hs_pcb170_cadj_Log2 OCs -2.4262873 -5.183666 0.3310918 0.08459568 8 hs_pcb180_cadj_Log2 OCs -2.0223411 -4.891328 0.8466454 0.16710270 $BIB$alpha_corrected [1] 0.0121022 $EDEN $EDEN$exwas_results exposure family coefficient minE maxE p.value 1 hs_dde_cadj_Log2 OCs -0.4702087 -2.5559924 1.615575 0.65860175 2 hs_ddt_cadj_Log2 OCs 0.4009790 -0.6531102 1.455068 0.45592311 3 hs_hcb_cadj_Log2 OCs -8.1803911 -14.4909796 -1.869803 0.01106328 4 hs_pcb118_cadj_Log2 OCs -1.0977685 -3.8953491 1.699812 0.44184084 5 hs_pcb138_cadj_Log2 OCs -1.1786063 -3.7056203 1.348408 0.36064718 6 hs_pcb153_cadj_Log2 OCs -1.5515330 -4.1586353 1.055569 0.24344895 7 hs_pcb170_cadj_Log2 OCs -0.3202816 -1.8331977 1.192635 0.67819988 8 hs_pcb180_cadj_Log2 OCs -0.4135072 -1.8704955 1.043481 0.57803554 $EDEN$alpha_corrected [1] 0.01384756 $KANC $KANC$exwas_results exposure family coefficient minE maxE p.value 1 hs_dde_cadj_Log2 OCs -2.15984812 -3.826289 -0.4934071 0.01107642 2 hs_ddt_cadj_Log2 OCs -0.01154892 -1.267423 1.2443256 0.98561997 3 hs_hcb_cadj_Log2 OCs -4.00761392 -7.181599 -0.8336290 0.01333342 4 hs_pcb118_cadj_Log2 OCs -2.80340364 -6.583489 0.9766814 0.14606908 5 hs_pcb138_cadj_Log2 OCs -2.63632131 -5.130332 -0.1423103 0.03828399 6 hs_pcb153_cadj_Log2 OCs -2.51562811 -4.823935 -0.2073216 0.03267949 7 hs_pcb170_cadj_Log2 OCs -1.29646005 -2.444243 -0.1486770 0.02683937 8 hs_pcb180_cadj_Log2 OCs -1.39850838 -2.563078 -0.2339385 0.01858855 $KANC$alpha_corrected [1] 0.01553731 $MoBA $MoBA$exwas_results exposure family coefficient minE maxE p.value 1 hs_dde_cadj_Log2 OCs -1.457757 -2.560167 -0.355347632 0.0095493749 2 hs_ddt_cadj_Log2 OCs -1.148283 -2.292547 -0.004019784 0.0492005854 3 hs_hcb_cadj_Log2 OCs -3.294045 -5.162940 -1.425149635 0.0005511926 4 hs_pcb118_cadj_Log2 OCs -1.000168 -2.590214 0.589879201 0.2176309682 5 hs_pcb138_cadj_Log2 OCs -1.934564 -3.410314 -0.458813747 0.0101898069 6 hs_pcb153_cadj_Log2 OCs -2.542868 -4.252530 -0.833206050 0.0035551176 7 hs_pcb170_cadj_Log2 OCs -1.505727 -2.548720 -0.462734545 0.0046617570 8 hs_pcb180_cadj_Log2 OCs -1.958968 -3.183695 -0.734241512 0.0017185942 $MoBA$alpha_corrected [1] 0.01209655 $Rhea $Rhea$exwas_results exposure family coefficient minE maxE p.value 1 hs_dde_cadj_Log2 OCs -1.05494477 -2.833861 0.72397135 0.24510916 2 hs_ddt_cadj_Log2 OCs -0.05756715 -1.260703 1.14556860 0.92528427 3 hs_hcb_cadj_Log2 OCs -5.14794959 -9.398718 -0.89718100 0.01761370 4 hs_pcb118_cadj_Log2 OCs -3.16975883 -6.312547 -0.02697095 0.04806604 5 hs_pcb138_cadj_Log2 OCs -2.41012750 -4.842452 0.02219693 0.05212769 6 hs_pcb153_cadj_Log2 OCs -2.34160066 -4.739251 0.05604920 0.05560145 7 hs_pcb170_cadj_Log2 OCs -0.59668424 -1.918566 0.72519716 0.37631391 8 hs_pcb180_cadj_Log2 OCs -0.85746219 -2.317065 0.60214090 0.24956546 $Rhea$alpha_corrected [1] 0.01471134 $INMASAB $INMASAB$exwas_results exposure family coefficient minE maxE p.value 1 hs_dde_cadj_Log2 OCs -2.1332539 -3.185178 -1.0813297 7.046300e-05 2 hs_ddt_cadj_Log2 OCs -0.8714851 -1.875583 0.1326125 8.892252e-02 3 hs_hcb_cadj_Log2 OCs -9.2905357 -13.492043 -5.0890284 1.464586e-05 4 hs_pcb118_cadj_Log2 OCs -7.4019264 -12.284062 -2.5197910 2.963007e-03 5 hs_pcb138_cadj_Log2 OCs -4.2831093 -7.150214 -1.4160047 3.412045e-03 6 hs_pcb153_cadj_Log2 OCs -5.0169565 -8.169270 -1.8646428 1.812731e-03 7 hs_pcb170_cadj_Log2 OCs -2.3555364 -3.846391 -0.8646819 1.956713e-03 8 hs_pcb180_cadj_Log2 OCs -2.6446000 -4.294145 -0.9950553 1.676413e-03 $INMASAB$alpha_corrected [1] 0.01400085 attr(,&quot;class&quot;) [1] &quot;list&quot; &quot;dsExWAS_meta&quot; head(res.meta) $BIB $BIB$exwas_results exposure family coefficient minE maxE p.value 1 hs_dde_cadj_Log2 OCs -1.6438877 -3.541887 0.2541115 0.08959152 2 hs_ddt_cadj_Log2 OCs 0.1091568 -2.060320 2.2786341 0.92144381 3 hs_hcb_cadj_Log2 OCs -6.1180786 -13.452346 1.2161893 0.10205803 4 hs_pcb118_cadj_Log2 OCs -7.1454343 -13.740344 -0.5505245 0.03370559 5 hs_pcb138_cadj_Log2 OCs -2.8928741 -7.834245 2.0484967 0.25119960 6 hs_pcb153_cadj_Log2 OCs -3.0742528 -8.365768 2.2172625 0.25483017 7 hs_pcb170_cadj_Log2 OCs -2.4262873 -5.183666 0.3310918 0.08459568 8 hs_pcb180_cadj_Log2 OCs -2.0223411 -4.891328 0.8466454 0.16710270 $BIB$alpha_corrected [1] 0.0121022 $EDEN $EDEN$exwas_results exposure family coefficient minE maxE p.value 1 hs_dde_cadj_Log2 OCs -0.4702087 -2.5559924 1.615575 0.65860175 2 hs_ddt_cadj_Log2 OCs 0.4009790 -0.6531102 1.455068 0.45592311 3 hs_hcb_cadj_Log2 OCs -8.1803911 -14.4909796 -1.869803 0.01106328 4 hs_pcb118_cadj_Log2 OCs -1.0977685 -3.8953491 1.699812 0.44184084 5 hs_pcb138_cadj_Log2 OCs -1.1786063 -3.7056203 1.348408 0.36064718 6 hs_pcb153_cadj_Log2 OCs -1.5515330 -4.1586353 1.055569 0.24344895 7 hs_pcb170_cadj_Log2 OCs -0.3202816 -1.8331977 1.192635 0.67819988 8 hs_pcb180_cadj_Log2 OCs -0.4135072 -1.8704955 1.043481 0.57803554 $EDEN$alpha_corrected [1] 0.01384756 $KANC $KANC$exwas_results exposure family coefficient minE maxE p.value 1 hs_dde_cadj_Log2 OCs -2.15984812 -3.826289 -0.4934071 0.01107642 2 hs_ddt_cadj_Log2 OCs -0.01154892 -1.267423 1.2443256 0.98561997 3 hs_hcb_cadj_Log2 OCs -4.00761392 -7.181599 -0.8336290 0.01333342 4 hs_pcb118_cadj_Log2 OCs -2.80340364 -6.583489 0.9766814 0.14606908 5 hs_pcb138_cadj_Log2 OCs -2.63632131 -5.130332 -0.1423103 0.03828399 6 hs_pcb153_cadj_Log2 OCs -2.51562811 -4.823935 -0.2073216 0.03267949 7 hs_pcb170_cadj_Log2 OCs -1.29646005 -2.444243 -0.1486770 0.02683937 8 hs_pcb180_cadj_Log2 OCs -1.39850838 -2.563078 -0.2339385 0.01858855 $KANC$alpha_corrected [1] 0.01553731 $MoBA $MoBA$exwas_results exposure family coefficient minE maxE p.value 1 hs_dde_cadj_Log2 OCs -1.457757 -2.560167 -0.355347632 0.0095493749 2 hs_ddt_cadj_Log2 OCs -1.148283 -2.292547 -0.004019784 0.0492005854 3 hs_hcb_cadj_Log2 OCs -3.294045 -5.162940 -1.425149635 0.0005511926 4 hs_pcb118_cadj_Log2 OCs -1.000168 -2.590214 0.589879201 0.2176309682 5 hs_pcb138_cadj_Log2 OCs -1.934564 -3.410314 -0.458813747 0.0101898069 6 hs_pcb153_cadj_Log2 OCs -2.542868 -4.252530 -0.833206050 0.0035551176 7 hs_pcb170_cadj_Log2 OCs -1.505727 -2.548720 -0.462734545 0.0046617570 8 hs_pcb180_cadj_Log2 OCs -1.958968 -3.183695 -0.734241512 0.0017185942 $MoBA$alpha_corrected [1] 0.01209655 $Rhea $Rhea$exwas_results exposure family coefficient minE maxE p.value 1 hs_dde_cadj_Log2 OCs -1.05494477 -2.833861 0.72397135 0.24510916 2 hs_ddt_cadj_Log2 OCs -0.05756715 -1.260703 1.14556860 0.92528427 3 hs_hcb_cadj_Log2 OCs -5.14794959 -9.398718 -0.89718100 0.01761370 4 hs_pcb118_cadj_Log2 OCs -3.16975883 -6.312547 -0.02697095 0.04806604 5 hs_pcb138_cadj_Log2 OCs -2.41012750 -4.842452 0.02219693 0.05212769 6 hs_pcb153_cadj_Log2 OCs -2.34160066 -4.739251 0.05604920 0.05560145 7 hs_pcb170_cadj_Log2 OCs -0.59668424 -1.918566 0.72519716 0.37631391 8 hs_pcb180_cadj_Log2 OCs -0.85746219 -2.317065 0.60214090 0.24956546 $Rhea$alpha_corrected [1] 0.01471134 $INMASAB $INMASAB$exwas_results exposure family coefficient minE maxE p.value 1 hs_dde_cadj_Log2 OCs -2.1332539 -3.185178 -1.0813297 7.046300e-05 2 hs_ddt_cadj_Log2 OCs -0.8714851 -1.875583 0.1326125 8.892252e-02 3 hs_hcb_cadj_Log2 OCs -9.2905357 -13.492043 -5.0890284 1.464586e-05 4 hs_pcb118_cadj_Log2 OCs -7.4019264 -12.284062 -2.5197910 2.963007e-03 5 hs_pcb138_cadj_Log2 OCs -4.2831093 -7.150214 -1.4160047 3.412045e-03 6 hs_pcb153_cadj_Log2 OCs -5.0169565 -8.169270 -1.8646428 1.812731e-03 7 hs_pcb170_cadj_Log2 OCs -2.3555364 -3.846391 -0.8646819 1.956713e-03 8 hs_pcb180_cadj_Log2 OCs -2.6446000 -4.294145 -0.9950553 1.676413e-03 $INMASAB$alpha_corrected [1] 0.01400085 #ExWAS with meta-analysis approachpooled approach (without covariables). Estimated execution time: approx. 4.218055 mins start_time &lt;- Sys.time() res.pooled &lt;- ds.exwas(&#39;hs_bp_sys ~ 1&#39;, type = &quot;pooled&quot;, exposures_family = &quot;OCs&quot;, Set = &#39;exposome_set&#39;, family = &#39;gaussian&#39;) [1] &quot;The computation of threshold for effective tests was not successful. NAs were generated on the correlation matrix so the calculation was aborted.&quot; end_time &lt;- Sys.time() end_time - start_time Time difference of 4.871074 mins res.pooled $exwas_results exposure family coefficient minE maxE p.value 1 hs_dde_cadj_Log2 OCs -3.6203404 -4.173032 -3.06764924 9.976229e-38 2 hs_ddt_cadj_Log2 OCs -2.0533429 -2.505415 -1.60127115 5.470142e-19 3 hs_hcb_cadj_Log2 OCs -7.5606414 -8.702722 -6.41856079 1.694248e-38 4 hs_pcb118_cadj_Log2 OCs -4.0522375 -5.209499 -2.89497594 6.744828e-12 5 hs_pcb138_cadj_Log2 OCs -3.0908785 -4.079692 -2.10206552 8.980604e-10 6 hs_pcb153_cadj_Log2 OCs -2.6037560 -3.655924 -1.55158813 1.233115e-06 7 hs_pcb170_cadj_Log2 OCs -0.5434277 -1.107247 0.02039150 5.888131e-02 8 hs_pcb180_cadj_Log2 OCs -0.5266027 -1.121772 0.06856693 8.288881e-02 $alpha_corrected [1] 0.0121022 attr(,&quot;class&quot;) [1] &quot;list&quot; &quot;dsExWAS_pooled&quot; head(res.pooled) $exwas_results exposure family coefficient minE maxE p.value 1 hs_dde_cadj_Log2 OCs -3.6203404 -4.173032 -3.06764924 9.976229e-38 2 hs_ddt_cadj_Log2 OCs -2.0533429 -2.505415 -1.60127115 5.470142e-19 3 hs_hcb_cadj_Log2 OCs -7.5606414 -8.702722 -6.41856079 1.694248e-38 4 hs_pcb118_cadj_Log2 OCs -4.0522375 -5.209499 -2.89497594 6.744828e-12 5 hs_pcb138_cadj_Log2 OCs -3.0908785 -4.079692 -2.10206552 8.980604e-10 6 hs_pcb153_cadj_Log2 OCs -2.6037560 -3.655924 -1.55158813 1.233115e-06 7 hs_pcb170_cadj_Log2 OCs -0.5434277 -1.107247 0.02039150 5.888131e-02 8 hs_pcb180_cadj_Log2 OCs -0.5266027 -1.121772 0.06856693 8.288881e-02 $alpha_corrected [1] 0.0121022 As we said, these previous formulas will fit GLMs between the exposures and the phenotype as follows: phenotype ~ exposure_1 + covar1 + ... + covarN phenotype ~ exposure_2 + covar1 + ... + covarN phenotype ~ exposure_3 + covar1 + ... + covarN ... phenotype ~ exposure_M + covar1 + ... + covarN The model is written as a string, where the left side term is the phenotype, and the right term are the covariates or confounders (e.g. variables to be adjusted for). A crude model is fitted in our example using phenotype ~ 1. In the case of having more covariates proceed as: phenotype ~ cov1 + cov2 + ... + covN. To visualize the results from the ExWAS, the ds.ExposomeClient package has the function ds.plotExwas(). It takes the output of ds.exwas() and creates two different visualizations depending on the argument “type”. In the next chunk we show how to generate a Manhattan-like plot with the p-values of the association between each exposure and the outcome colored by families of exposures. The vertical red line stands for the significant level corrected by the effective number of tests. # One plot per cohort ds.plotExwas(res.meta, type=&quot;manhattan&quot;) $BIB $EDEN $KANC $MoBA $Rhea $INMASAB # One plot for the whole population ds.plotExwas(res.pooled, type=&quot;manhattan&quot;) Given the nature of the “Manhattan plots,” it should be noted that this kind of visualizations is more indicated when performing a big ExWAS study rather than when focusing in a group of exposures such is the present case. We can also generate a plot showing the effects (beta values) and their confidence intervals with: # One plot per cohort ds.plotExwas(res.meta, type=&quot;effect&quot;) $BIB $EDEN $KANC $MoBA $Rhea $INMASAB # One plot for the whole population ds.plotExwas(res.pooled, type=&quot;effect&quot;) To replicate the findings from (Warembourg et al. 2019), we will next repeat the pooled ExWAS approach process but including all previously mentioned adjusting covariates, with the exception of the parent’s country of origin, which presented some problems as we saw during the descriptive inspection. As you can see, the order to adjust the models by cohort is given separately to the function, directly with the argument “adjust.by.study”. #Adjust by cohort and other covariates. Estimated execution time: approx. 5.670872 mins start_time &lt;- Sys.time() res.pooled_adjusted &lt;- ds.exwas(&quot;hs_bp_sys ~ hs_child_age_days_None + hs_c_height_None + e3_sex_None + h_age_None + h_mbmi_None&quot;, type = &quot;pooled&quot;, adjust.by.study = TRUE, exposures_family = &quot;OCs&quot;, Set = &quot;exposome_set&quot;, family = &quot;gaussian&quot;) end_time &lt;- Sys.time() end_time - start_time res.pooled_adjusted As it can be seen, we are able to validate the main findings presented for the paper, reporting an inverse association between the serum concentration of some of these compounds and the systolic blood pressure levels of children. 2.4 Feature selection with penalized methods In this subsection, we present how to perform variable selection with penalized regression methods in an exposome context. As previously mentioned, the “dsMTL” package allows the implementation of a federated version of conventional regularized regression techniques (such as Lasso, Ridge or Elastic-net), both in the context of continuous or binary outcomes (linear and logistic regression, respectively). Here, we will show how to apply these methods to the HELIX data, focusing in the systolic blood pressure of children as the main outcome. Since most of the functions in the “dsMTL” package require data of each cohort to be passed as separate matrices for the predictors and the outcome, in the next chunks of code we will show how to transform the input HELIX dataset from the current exposomeSet format into two matrices with the required format in DataSHIELD. For that, we will start generating two data.frames, one for exposure data and one for the outcome data. First, we will use the function ds.exposures_pData(), which can extracts exposures, phenotypes or combined data and saves it to a data frame on the server side. #With the &quot;name&quot; argument, we can specify the name of the new R object to be created, if no name argument is provided, the new object will be named &quot;set_table&quot; where &quot;set&quot; is the inputted argument. ds.exposures_pData(&#39;exposome_set&#39;, type = &quot;exposures&quot;, exposures_type = &quot;numeric&quot;, name = &#39;table_exposures&#39;) ds.exposures_pData(&#39;exposome_set&#39;, type = &quot;phenotypes&quot;, exposures_type = &quot;numeric&quot;, name = &#39;table_phenotypes&#39;) #we can check the objects created in the remote session for each cohort by typing ds.ls() Now we have two different objects for exposures and phenotype data, we can continue with the data preparation. # We start by assigning the outcome Systolic Blood pressure to a new R object of the type numeric vector called &quot;Y&quot; in the server side. ds.assign(toAssign=&quot;table_phenotypes$hs_bp_sys&quot;, newobj=&quot;Y&quot;, datasources = conns) # Check if there is NA values in the phenotype. ds.numNA(&quot;Y&quot;) # Replace NA values by the cohort mean. Y_means &lt;- ds.mean(x = &quot;Y&quot;,type = &quot;split&quot;,save.mean.Nvalid = F,datasources = conns)$Mean.by.Study ds.replaceNA(x = &quot;Y&quot;, forNA = Y_means[,1], newobj = &quot;Y_imp&quot;, datasources = conns) # We extract the adjusting covariates from the phenotype dataset and assign them to a new dataframe names &quot;X_confounders&quot; keep_conf &lt;- which(ds.colnames(&#39;table_phenotypes&#39;)[[1]] %in% c(&quot;hs_child_age_days_None&quot;,&quot;hs_c_height_None&quot;,&quot;e3_sex_None&quot;,&quot;h_age_None&quot;,&quot;h_mbmi_None&quot;)) ds.dataFrameSubset(df.name = &quot;table_phenotypes&quot;, V1.name = NULL, V2.name = NULL, Boolean.operator = NULL,keep.cols = keep_conf, rm.cols = NULL, keep.NAs = NULL, newobj = &quot;X_confounders&quot;, datasources = conns, notify.of.progress = FALSE) # We merge confounders data with exposures and assign the result to an R object calles &quot;X&quot;. ds.dataFrame(x = c(&quot;table_exposures&quot;,&quot;X_confounders&quot;), completeCases = TRUE, newobj = &quot;X&quot;, datasources = conns) # We again check dimensions and attribute names for the resulting objects. ds.dim(&quot;X&quot;) ds.class(&quot;Y&quot;) ds.length(&quot;Y&quot;) ds.colnames(&quot;X&quot;)[[1]][1:5] # We coerce both Xs and Y into matrices. #ds.asMatrix(x.name = &quot;Y&quot;, newobj = &quot;Y&quot;, datasources = NULL) ds.asMatrix(x.name = &quot;table_exposures&quot;, newobj = &quot;X&quot;, datasources = NULL) ds.asMatrix(x.name = &quot;Y&quot;, newobj = &quot;Y&quot;, datasources = NULL) ds.asMatrix(x.name = &quot;Y_imp&quot;, newobj = &quot;Y_imp&quot;, datasources = NULL) # We assign both matrices to R objects in the client-side. X=&quot;X&quot;; Y=&quot;Y&quot;; Y_imp=&quot;Y_imp&quot; Once we have the data in the right format, we can proceed to perform variable selection with penalized methods. Available functions in the package for such purpose include: ds.LS_Lasso(): Solver of regression with Lasso. ds.LR_Lasso(): Solver of logistic regression with Lasso. ds.Lasso_Train(): Train a regularization tree with Lasso for a sequence of penalty values (than can be either provided by the user, or directly estimated from the data). ds.Lasso_CVInSite(): In-site cross-validation procedure for selecting the optimal penalty. In all these functions, there is an argument called “C”, which is the hyperparameter for the Ridge regression L2 penalty. Thus, by tuning both the L1 penalty and the C argument (L2 term), one would be able to chose between a Lasso, Ridge or Elastic-Net regression. Likewise, there is an argument called “opts”, which allow controlling the optimization algorithm employed to minimize the sum of squared errors (SSE) (objective function). Additional details regarding the loss function implemented in these models can be found in the supplementary material of (Cao2021.08.26.457778?). Within the “opts” argument we find: “init”: It determines the starting point. “maxIter”: It is the maximized iteration number. “ter”: It refers to the termination rule used to determine the convergence of the algorithm. There are three termination rules available for ds.lasso. The first rule checks whether the current objective value was close enough to 0. The second rule investigates the last two objective values and checks whether the decline was close enough to 0. The third rule allowed the optimization to be performed for a certain maximum number of iterations. “tol”: It refers to the precision of the convergence and determines the termination of the program. #Default values for the opts argument. opts=list();opts$init=0; opts$maxIter=10; opts$tol=0.01; opts$ter=2; A summary of the whole pipeline that one could follow in DataSHIELD for performing feature selection with Lasso regression can be found in (Figure 2). Figure 2.2: Figure 2. DataSHIELD for the implementation of penalized Lasso regression in a federated framework. 2.4.1 ds.LS_Lasso() function. With the ds.LS_Lasso() function, we can apply the lasso solver of regression for a particular value of the lambda penalty. Input arguments available in the function include: X: The design matrices of multiple cohorts. Y: Label vectors of multiple cohorts. lam: Input lambda value. C: The hyper-parameter associated with L2 term. opts: Options controlling the optimization procedure. datasources: The connections of servers. nDigits: The number of digits rounded for each number prepared for network transmission. W: The current estimate of the variables (if available). Note that if we set lam=0 and C&gt;0 we will do Ridge regression, lam&gt;0 and C=0 we will do Lasso, while any other combination of these both will be Elastic-Net. The output of this function comprises: The vector of weights estimated for input predictors. The converged result of optimization. The proximal point of W and the non-smooth part of objective. In the next chunk, we apply this function to our example dataset, setting the value of the lambda penalty to “0.5.” For this, we will test the association between the 174 predictors and the continuous outcome BMI Z-Score. In case we were interested in modeling a binary outcome, we should use the ds.LR_Lasso() function instead, which share exactly the same arguments and options. # Estimated execution time: approx. 17.05 seconds. set.seed(123) m1=ds.LS_Lasso(X=X, Y=Y_imp, lam=0.5, C=0, opts, datasources=conns, nDigits=15) # Show the number of selected variables by the model for the assessed lambda sum(m1$w!=0) [1] 79 In our example, with this lambda penalty, 79 variables are selected as significant contributors to the outcome systolic blood pressure. Now, we can plot estimated coefficients from the model. plot(m1$w, xlab=&quot;index of coefficients&quot;, ylab=&quot;values&quot;) Please, note that input variables are not standardized previous to the modeling in ds.LS_Lasso(), while, in the local solution glmnet(), the default argument is standardize=TRUE. 2.4.2 ds.Lasso_Train() function. Instead of introducing a single value of lambda and fitting the model, a whole lambda sequence can be tested (either if it has been defined by the user, or if it has been estimated from the data). For that purpose, we must use the function ds.Lasso_Train(), which trains a whole regularization tree with Lasso for a set of penalty values. Some input arguments available here and not present in the previous function are: type: Regression(=regress) or classification(=classify). nlambda: The length of lambda sequence. lam_ratio: This is an option affecting how the lambda sequence is extracted from the data. It refers to the ratio: \\(min(lambda) / max(lambda)\\). lambda: The lambda sequence. intercept: Use intercept(=TRUE) or non-intercept(=FALSE) model. The process of lambdas estimation from the data in this function is governed by two arguments: “nlambda” and “lam_ratio”. First, the lambda max is determined as the smallest value of lambda for which no parameters are selected. In the next chunk, we show the code lines of the function source code that extract the lambda max value from the data. xys = DSI::datashield.aggregate(datasources, call(&quot;xtyDS&quot;, X, Y)) #matrix multiplication x * t(y) xys = rowSums(do.call(cbind, xys))/sum(nSubs) xy_norm = max(abs(xys)) The determination of λmin and the number of grid points seems less principled. The λmin is calculated as \\(λmin=λratio∗λmax\\), and then a grid of n equally spaced points on the logarithmic scale between λmin and λmax is generated. The output of the ds.Lasso_Train() function is a list composed of: A matrix with as many columns as lambdas and as many rows as variables including the estimated coefficients for each variable-lambda.^ A vector with the sequence of lambdas (either if they were estimated from data or introduced by the user). Next, we show how to apply this function to our case study, estimating a sequence of 4 lambda penalties from the data. # Estimated execution time: approx. 56.79 seconds. m2=ds.Lasso_Train(X=X, Y=Y_imp, type=&quot;regress&quot;, nlambda=4, lam_ratio=0.0001, C=0, opts=opts,datasources=conns, nDigits=15) str(m2) List of 6 $ ws : num [1:79, 1:4] 0 0 0 0 0 ... ..- attr(*, &quot;dimnames&quot;)=List of 2 .. ..$ : NULL .. ..$ : chr [1:4] &quot;Lam=38347.3&quot; &quot;Lam=1779.92&quot; &quot;Lam=82.62&quot; &quot;Lam=3.83&quot; $ Logs : num [1:4, 1:2] 1 5 3 3 1 23 21 21 $ Obj : num [1:12] 5027 1142 1089 1060 1033 ... $ gamma : num [1:4] 1 262144 262144 262144 $ type : chr &quot;regress&quot; $ lam_seq: num [1:4] 38347.3 1779.92 82.62 3.83 From the output of this function, the number of selected variables for each lambda value can also be extracted: fun &lt;- function(x) { length(which(x != 0)) } apply(m2$ws,2,fun) Lam=38347.3 Lam=1779.92 Lam=82.62 Lam=3.83 1 3 15 75 And we can plot the results (regularization tree). If the estimation of the λmax penalty has been performed correctly, all horizontal lines in the plot should begin with w=0, since, as we said before, by definition, the λmax is the smallest value of lambda for which no parameters are selected. matplot(t(m2$ws), type = &quot;l&quot;, main=&quot;solution Path&quot;, xlab = &quot;lambda&quot;, ylab = &quot;coefficients&quot;) Please, note that the values in the X axis refer to the appearance order of each lambda in the lambda sequence vector, i.e., Lam1=38347.3, Lam2=1779.92, Lam3=82.62 and Lam4=3.83 In the case of the lambda sequence is defined by the user, we would have: # Estimated execution time: approx. 36.23 seconds. m3=ds.Lasso_Train(X=X, Y=Y_imp, type=&quot;regress&quot;, nlambda=2, lambda=c(0.2,0.6), C=0, opts=opts,datasources=conns, nDigits=15) #Show number of selected variables and plot coefficients. apply(m3$ws,2,fun) Lam=0.2 Lam=0.6 79 78 matplot(t(m3$ws), type = &quot;l&quot;, main=&quot;solution Path&quot;, xlab = &quot;lambda&quot;, ylab = &quot;coefficients&quot;) An important drawback of the current version of the ds.Lasso_Train() function, is that it does not allow to force the inclusion of covariates in models, which in glmnet() is achieved through the argument “penalty.factor” by reducing to 0 the penalty to be applied to their coefficients. Other important difference is the type of optimization algorithm employed for the estimation of coefficients. In comparison to glmnet(), which implements the coordinate descent (Wright2015?), ds.Lasso_Train() implements an optimization procedure based on the proximal algorithm framework (OPT-003?). 2.4.3 ds.Lasso_CVInSite() function. As in glmnet(), ds.Lasso also allows the selection of the optimal lambda by a k-fold cross-validation procedure. This is done in “dsMTL” with the function ds.Lasso_CVInSite(), which has practically the same arguments than previous functions, except for the “nfolds” argument, referring to the number of folds for the CV procedure. From the application of this function to our case study, we can estimate a lambda sequence of 5 values with a 5-fold CV procedure: #NOT DEFINITIVE # Estimated execution time: approx. 8.17 mins. cvResult=ds.Lasso_CVInSite(X=X, Y=Y_imp, type=&quot;regress&quot;, lam_ratio=0.5, nlambda=5, opts=opts, C=0, datasources=conns, nDigits=4, nfolds=10) # Boxplot showing the averaged MSE obtained for lambda values over folds boxplot(cvResult$mse_fold, names=as.character(round(colMeans(cvResult$lam_seq), 3)), xlab=&quot;averaged lambda over folds&quot;, ylab=&quot;mean squared error&quot;) From this model, we could select the optimal lambda value directly from the output with the “cvResult$lambda.min” argument, and then fit a new model with optimal hyperparameters. #NOT DEFINITIVE # Estimated execution time: approx. 1.40507 mins. # Optimal lambda from CV cvResult$lambda.min # Training a new model with selected hype-parameter m4=ds.Lasso_Train(X=X, Y=Y_imp, type=&quot;regress&quot;, lambda=cvResult$lambda.min, nlambda=5, opts=opts, C=0, datasources=conns, nDigits=4) # Number of selected variables and their estimated coefficients apply(m4$ws,2,fun) plot(m4$ws, xlab=&quot;index of coefficients&quot;, ylab=&quot;values&quot;) As previously mentioned, all these functions can be adapted for Ridge and Elastic-Net regression by properly tuning the “C” argument. datashield.logout(conns) References. "],["references..html", "3 References.", " 3 References. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
